{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations for python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first time to create venv and install packages\n",
    "\n",
    "# %conda create -n corrid-dev anaconda -y\n",
    "# %conda activate corrid-dev -y\n",
    "\n",
    "# %conda install -n corrid-dev pandas -y\n",
    "\n",
    "# %conda install pip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess logs: Read, Encode categorical attributes by One Hot Encoder, and Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode: data_bpic17_readyToUse_preprocessed_for_adaptation_classification.csv\n",
      "       ApplicationType_Limit raise  ApplicationType_New credit  LoanGoal_Car  \\\n",
      "0                                0                           1             0   \n",
      "1                                0                           1             0   \n",
      "2                                0                           1             0   \n",
      "3                                0                           1             1   \n",
      "4                                0                           1             0   \n",
      "...                            ...                         ...           ...   \n",
      "31408                            0                           1             1   \n",
      "31409                            0                           1             0   \n",
      "31410                            0                           1             0   \n",
      "31411                            0                           1             1   \n",
      "31412                            0                           1             0   \n",
      "\n",
      "       LoanGoal_Caravan / Camper  LoanGoal_Existing loan takeover  \\\n",
      "0                              0                                1   \n",
      "1                              0                                0   \n",
      "2                              0                                0   \n",
      "3                              0                                0   \n",
      "4                              0                                0   \n",
      "...                          ...                              ...   \n",
      "31408                          0                                0   \n",
      "31409                          0                                1   \n",
      "31410                          0                                0   \n",
      "31411                          0                                0   \n",
      "31412                          0                                0   \n",
      "\n",
      "       LoanGoal_Extra spending limit  LoanGoal_Home improvement  \\\n",
      "0                                  0                          0   \n",
      "1                                  0                          1   \n",
      "2                                  0                          1   \n",
      "3                                  0                          0   \n",
      "4                                  0                          1   \n",
      "...                              ...                        ...   \n",
      "31408                              0                          0   \n",
      "31409                              0                          0   \n",
      "31410                              0                          1   \n",
      "31411                              0                          0   \n",
      "31412                              0                          1   \n",
      "\n",
      "       LoanGoal_Motorcycle  LoanGoal_Not speficied  \\\n",
      "0                        0                       0   \n",
      "1                        0                       0   \n",
      "2                        0                       0   \n",
      "3                        0                       0   \n",
      "4                        0                       0   \n",
      "...                    ...                     ...   \n",
      "31408                    0                       0   \n",
      "31409                    0                       0   \n",
      "31410                    0                       0   \n",
      "31411                    0                       0   \n",
      "31412                    0                       0   \n",
      "\n",
      "       LoanGoal_Other see explanation  ...   duration  FirstWithdrawalAmount  \\\n",
      "0                                   0  ...  13.248566                20000.0   \n",
      "1                                   0  ...   6.134470                  500.0   \n",
      "2                                   0  ...  12.819864                15000.0   \n",
      "3                                   0  ...  26.988859                 3726.0   \n",
      "4                                   0  ...  31.750191                35000.0   \n",
      "...                               ...  ...        ...                    ...   \n",
      "31408                               0  ...  22.644617                 5000.0   \n",
      "31409                               0  ...   5.576960                 8304.0   \n",
      "31410                               0  ...  22.625626                10000.0   \n",
      "31411                               0  ...  22.926296                 8304.0   \n",
      "31412                               0  ...  15.509351                20000.0   \n",
      "\n",
      "       MonthlyCost  NumberOfTerms  OfferedAmount  open_cases  month  weekday  \\\n",
      "0           498.29             44        20000.0         815      1        3   \n",
      "1           200.00             33         6000.0         431      1        3   \n",
      "2           158.98            120        15000.0         790      1        2   \n",
      "3           252.73             72        15700.0        1240      1        1   \n",
      "4           366.08            120        35000.0         340      1        2   \n",
      "...            ...            ...            ...         ...    ...      ...   \n",
      "31408        97.40             60         5000.0        1193      1        3   \n",
      "31409       150.00            127        15000.0        1451      1        0   \n",
      "31410       106.46            120        10000.0         697      1        4   \n",
      "31411       450.00             77        30000.0         556      1        1   \n",
      "31412       297.81             77        20000.0        1142      1        4   \n",
      "\n",
      "       hour  treatment  \n",
      "0         9          1  \n",
      "1        11          0  \n",
      "2        12          1  \n",
      "3         8          1  \n",
      "4         9          0  \n",
      "...     ...        ...  \n",
      "31408    11          1  \n",
      "31409    13          0  \n",
      "31410    10          1  \n",
      "31411    14          1  \n",
      "31412     6          0  \n",
      "\n",
      "[31413 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# encode logs (string features with OneHotEncoder)\n",
    "import pandas as pd\n",
    "\n",
    "logs_folder = './logs/'\n",
    "bpic17_logs_with_interventions_path = 'data_bpic17_readyToUse_preprocessed_for_adaptation_classification.csv'\n",
    "bpic17_logs_with_interventions_path_encoded = 'data_bpic17_readyToUse_preprocessed_for_adaptation_classification_encoded.csv'\n",
    "\n",
    "def encode(dataframe):\n",
    "    from sklearn import preprocessing\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown='ignore', sparse=False, dtype=int)\n",
    "    return enc.fit_transform(dataframe), enc\n",
    "\n",
    "def store_logs(dataframe, path):\n",
    "    dataframe.to_csv(logs_folder + path, columns=dataframe.columns, index=False)\n",
    "\n",
    "def load_logs(path):\n",
    "    return pd.read_csv(logs_folder + path, quotechar=\"'\")\n",
    "\n",
    "print(f'encode: {bpic17_logs_with_interventions_path}')\n",
    "data_df = load_logs(bpic17_logs_with_interventions_path)\n",
    "\n",
    "column_names_to_encode = ['ApplicationType', 'LoanGoal',]\n",
    "columns_to_encode = data_df.loc[:, column_names_to_encode]\n",
    "encoded_columns, encoder = encode(columns_to_encode)\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out())\n",
    "\n",
    "data_df_without_encoded_columns = data_df.drop(column_names_to_encode, axis='columns')\n",
    "data_encoded_df = encoded_df.join(data_df_without_encoded_columns)\n",
    "# data_encoded_df = data_encoded_df.reset_index()\n",
    "print(data_encoded_df)\n",
    "\n",
    "store_logs(data_encoded_df, bpic17_logs_with_interventions_path_encoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load logs & prepare for classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_pre_process: data_bpic17_readyToUse_preprocessed_for_adaptation_classification_encoded.csv\n",
      "Columns before removal:\n",
      "['ApplicationType_Limit raise', 'ApplicationType_New credit', 'LoanGoal_Car', 'LoanGoal_Caravan / Camper', 'LoanGoal_Existing loan takeover', 'LoanGoal_Extra spending limit', 'LoanGoal_Home improvement', 'LoanGoal_Motorcycle', 'LoanGoal_Not speficied', 'LoanGoal_Other see explanation', 'LoanGoal_Remaining debt home', 'LoanGoal_Unknown', 'LoanGoal_other', 'RequestedAmount', 'CreditScore', 'timesincefirstcase', 'duration', 'FirstWithdrawalAmount', 'MonthlyCost', 'NumberOfTerms', 'OfferedAmount', 'open_cases', 'month', 'weekday', 'hour', 'treatment']\n",
      "Columns after removal:\n",
      "['ApplicationType_Limit raise', 'ApplicationType_New credit', 'LoanGoal_Car', 'LoanGoal_Caravan / Camper', 'LoanGoal_Existing loan takeover', 'LoanGoal_Extra spending limit', 'LoanGoal_Home improvement', 'LoanGoal_Motorcycle', 'LoanGoal_Not speficied', 'LoanGoal_Other see explanation', 'LoanGoal_Remaining debt home', 'LoanGoal_Unknown', 'LoanGoal_other', 'RequestedAmount', 'CreditScore', 'timesincefirstcase', 'duration', 'FirstWithdrawalAmount', 'MonthlyCost', 'NumberOfTerms', 'OfferedAmount', 'open_cases', 'month', 'weekday', 'hour', 'treatment']\n",
      "\n",
      "log_pre_process: sample_sequence_simulation_logs_multi_adapted_noisy_encoded.csv\n",
      "Columns before removal:\n",
      "['trace_id', 'event:event_name@A', 'event:event_name@B', 'event:event_name@C', 'event:event_name@D', 'event:event_name@E', 'event:event_name@F', 'event:event_name@I', 'event:event_name@process end event', 'event:event_name@process start event', 'event:concept:name@A', 'event:concept:name@B', 'event:concept:name@C', 'event:concept:name@D', 'event:concept:name@E', 'event:concept:name@F', 'event:concept:name@I', 'event:concept:name@process end event', 'event:concept:name@process start event', 'event:adaptation_action@insert', 'event:adaptation_action@no-action', 'event:adaptation_action@skip', 'event:@@index', 'event:@@case_index', 'event:start_weekday', 'event:resource', 'event:duration', 'event:trace_id', 'succession:concept:name@A#B', 'succession:concept:name@B#C', 'succession:concept:name@C#D', 'succession:concept:name@D#E', 'succession:concept:name@D#F', 'succession:concept:name@E#F', 'succession:concept:name@F#process end event', 'succession:concept:name@process end event#I', 'succession:concept:name@process start event#A', 'trace:cycle_time', 'adaptation_action']\n",
      "Columns after removal:\n",
      "['trace_id', 'event:start_weekday', 'trace:cycle_time', 'adaptation_action']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def log_pre_process(csv_file_path, memory_reduction, columns_to_drop=[]):\n",
    "    print(f'log_pre_process: {csv_file_path}')\n",
    "    data_df = load_logs(csv_file_path)\n",
    "\n",
    "    print('Columns before removal:')\n",
    "    list_of_column_names = list(data_df.columns)\n",
    "    print(list_of_column_names)\n",
    "\n",
    "    data_df = data_df.drop(columns=columns_to_drop)\n",
    "\n",
    "    print('Columns after removal:')\n",
    "    list_of_column_names = list(data_df.columns)\n",
    "    print(list_of_column_names)\n",
    "    print()\n",
    "\n",
    "    slice_start_col = 0\n",
    "    slice_end_col = len(data_df.columns)-1\n",
    "\n",
    "    values = data_df.iloc[:, slice_start_col:slice_end_col]\n",
    "    classes = data_df.iloc[:, slice_end_col:]\n",
    "\n",
    "    # enc = preprocessing.OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    # values = enc.fit_transform(values[:2])\n",
    "\n",
    "    # enc2 = preprocessing.OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    # data_df = enc2.fit_transform(data_df)\n",
    "\n",
    "    data = (values, classes)\n",
    "\n",
    "    return data, list_of_column_names[:-1], data_df\n",
    "\n",
    "\n",
    "bpic17_logs_columns_to_drop = []\n",
    "bpic17_logs_with_interventions, bpic17_logs_with_interventions_column_names, bpic17_logs_with_interventions_df = log_pre_process(bpic17_logs_with_interventions_path_encoded, memory_reduction=False, columns_to_drop=bpic17_logs_columns_to_drop)\n",
    "\n",
    "synthetic_logs_with_adaptations_path = 'sample_sequence_simulation_logs_multi_adapted_noisy_encoded.csv'\n",
    "synthetic_logs_columns_to_drop = [\"event:event_name@A\",\"event:event_name@B\",\"event:event_name@C\",\"event:event_name@D\",\"event:event_name@E\",\"event:event_name@F\",\"event:event_name@I\",\"event:event_name@process end event\",\"event:event_name@process start event\",\"event:concept:name@A\",\"event:concept:name@B\",\"event:concept:name@C\",\"event:concept:name@D\",\"event:concept:name@E\",\"event:concept:name@F\",\"event:concept:name@I\",\"event:concept:name@process end event\",\"event:concept:name@process start event\",\"event:adaptation_action@insert\",\"event:adaptation_action@no-action\",\"event:adaptation_action@skip\",\"event:@@index\",\"event:@@case_index\",\"event:trace_id\",\"succession:concept:name@A#B\",\"succession:concept:name@B#C\",\"succession:concept:name@C#D\",\"succession:concept:name@D#E\",\"succession:concept:name@D#F\",\"succession:concept:name@E#F\",\"succession:concept:name@F#process end event\",\"succession:concept:name@process end event#I\",\"succession:concept:name@process start event#A\", \"event:resource\", \"event:duration\"]\n",
    "synthetic_logs_with_adaptations, synthetic_logs_with_adaptations_column_names, synthetic_logs_with_adaptations_df = log_pre_process(synthetic_logs_with_adaptations_path, memory_reduction=False, columns_to_drop=synthetic_logs_columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Classifier comparison (now just Decision Tree and print the tree model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: bpic17_logs_with_interventions\n",
      "\n",
      "\n",
      "Classifier: Nearest Neighbors\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.5369588705722823\n",
      "\n",
      "\n",
      "Classifier: Decision Tree\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.7843151284101866\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.6578081863941145\n",
      "\n",
      "\n",
      "Classifier: Neural Net (Multi-layer Perceptron)\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.43274943807587984\n",
      "\n",
      "\n",
      "Classifier: AdaBoost\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.6534803446805135\n",
      "\n",
      "\n",
      "Classifier: Gaussian Naive Bayes\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.6559218882855672\n",
      "\n",
      "\n",
      "Classifier: QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arash/opt/anaconda3/envs/corrid-dev/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/arash/opt/anaconda3/envs/corrid-dev/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/arash/opt/anaconda3/envs/corrid-dev/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/arash/opt/anaconda3/envs/corrid-dev/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/arash/opt/anaconda3/envs/corrid-dev/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/arash/opt/anaconda3/envs/corrid-dev/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/arash/opt/anaconda3/envs/corrid-dev/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/arash/opt/anaconda3/envs/corrid-dev/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/arash/opt/anaconda3/envs/corrid-dev/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/arash/opt/anaconda3/envs/corrid-dev/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10-fold cross-validation mean weighted F1: 0.43542015153410907\n",
      "\n",
      "\n",
      "Dataset: synthetic_logs_with_adaptations\n",
      "\n",
      "\n",
      "Classifier: Nearest Neighbors\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.7586216957631601\n",
      "\n",
      "\n",
      "Classifier: Decision Tree\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.9237324182574183\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.8789572865722868\n",
      "\n",
      "\n",
      "Classifier: Neural Net (Multi-layer Perceptron)\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.5948695394413764\n",
      "\n",
      "\n",
      "Classifier: AdaBoost\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.8264897957330447\n",
      "\n",
      "\n",
      "Classifier: Gaussian Naive Bayes\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.75808712722691\n",
      "\n",
      "\n",
      "Classifier: QDA\n",
      "\n",
      "10-fold cross-validation mean weighted F1: 0.7580498361026952\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "outputs_folder = './outputs/'\n",
    "decision_tree_output_file_name = 'output_decision_trees.txt'\n",
    "multi_classification_output_file_name = 'output_multiple_classification.txt'\n",
    "\n",
    "classifier_names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    # \"Linear SVM\",\n",
    "    # \"RBF SVM\",\n",
    "    # \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net (Multi-layer Perceptron)\",\n",
    "    \"AdaBoost\",\n",
    "    \"Gaussian Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    # SVC(kernel=\"linear\", C=0.025),\n",
    "    # SVC(gamma=2, C=1),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=4, min_samples_leaf=2, ccp_alpha=0.003),\n",
    "    RandomForestClassifier(max_depth=6, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "datasets_df = [\n",
    "    bpic17_logs_with_interventions_df,\n",
    "    synthetic_logs_with_adaptations_df\n",
    "]\n",
    "\n",
    "datasets = [\n",
    "    bpic17_logs_with_interventions,\n",
    "    synthetic_logs_with_adaptations\n",
    "]\n",
    "\n",
    "dataset_names = [\n",
    "    \"bpic17_logs_with_interventions\",\n",
    "    \"synthetic_logs_with_adaptations\"\n",
    "]\n",
    "\n",
    "dataset_feature_names = [\n",
    "    bpic17_logs_with_interventions_column_names,\n",
    "    synthetic_logs_with_adaptations_column_names\n",
    "]\n",
    "\n",
    "multi_classification_output_file = open(file=outputs_folder + multi_classification_output_file_name, mode='w')\n",
    "decision_tree_output_file = open(file=outputs_folder + decision_tree_output_file_name, mode='w')\n",
    "\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    \n",
    "    X, y = ds\n",
    "\n",
    "    out_text = f'Dataset: {dataset_names[ds_cnt]}\\n\\n'\n",
    "    print(out_text)\n",
    "    multi_classification_output_file.write(out_text)\n",
    "    decision_tree_output_file.write(out_text)\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for classifier_name, classifier in zip(classifier_names, classifiers):\n",
    "        \n",
    "        out_text_classifier = f'Classifier: {classifier_name}'\n",
    "        out_text_parameters = f'\\nParameters: {classifier.get_params()}'\n",
    "\n",
    "        print(out_text_classifier)\n",
    "        multi_classification_output_file.write(out_text_classifier + out_text_parameters)\n",
    "\n",
    "\n",
    "        scores = cross_val_score(classifier, X, y.values.ravel(), cv=10, scoring='f1_weighted')\n",
    "        \n",
    "        out_text = f'\\n10-fold cross-validation mean weighted F1: {numpy.mean(scores)}\\n\\n'\n",
    "\n",
    "        print(out_text)\n",
    "        multi_classification_output_file.write(out_text)\n",
    "\n",
    "        if classifier_name == 'Decision Tree':\n",
    "            classifier.fit(X, y.values.ravel())\n",
    "            text_representation = tree.export_text(classifier, feature_names=dataset_feature_names[ds_cnt])\n",
    "            decision_tree_output_file.write(out_text_classifier + out_text_parameters)\n",
    "            out_text_tree = f'\\n\\nDecision Tree on all training data:\\n{text_representation}\\n\\n'\n",
    "            decision_tree_output_file.write(out_text_tree)\n",
    "\n",
    "multi_classification_output_file.close()\n",
    "decision_tree_output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corrid-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov  4 2022, 11:11:31) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34ff90f5239f9160625527e13c748f95b5880a9ad27056497ef1c46bfe84f008"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
